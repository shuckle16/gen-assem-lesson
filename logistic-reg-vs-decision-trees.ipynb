{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncaa = pd.read_csv(\"march-madness.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A note about the data: each row represents a school-season.\n",
    "\n",
    "* Overall_W is the number of Wins\n",
    "* Overall_SRS is the StRength of Schedule that year. How difficult were your opponents?\n",
    "* made_it is our target: Did the school make it to the March Madness Tournament?\n",
    "\n",
    "So in 1995, the Air Force Academy had 8 wins, had a negative strength of schedule (below average), and didn't make it to the tournament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncaa.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick glance at the summary stats of the data with `describe`.\n",
    "\n",
    "Question: What are the first and last years in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncaa.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below is nice. It shows that Wins and SRS are mostly related. And that getting into the tournament is associated with being in the upper right hand corner of the plot. There are some edge cases, though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot('Overall_W', 'Overall_SRS', data = ncaa, hue = 'made_it')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare our data for a 2 variable logistic regression. How are Overall Wins and Overall Strength of Schedule associated with the odds of making it into the tournament?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ncaa[['Overall_W','Overall_SRS']]\n",
    "y = ncaa.made_it\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's understand the predictions and look at the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregpred = logreg.predict(X)\n",
    "\n",
    "confusion_matrix(logregpred, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(logregpred, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `DecisionTreeClassifier` from `sklearn` to fit a decision tree model!\n",
    "\n",
    "Build a confusion matrix and give an accuracy score for the model.\n",
    "\n",
    "Hint: the format is very similar to the logistic regression above.\n",
    "    \n",
    "Questions to ask your neighbor: What does `max_depth` do? How would you look this up?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model is better? Discuss with your neighbor why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If there's time...\n",
    "\n",
    "Add `year` back into the models. Did accuracy improve for either model?\n",
    "\n",
    "Write a sentence why I should have used `train_test_split` to split the data up before building the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Make 2 scatterplots, similar to the one above, but color the dots by whether or not the logistic regression and the decision tree made a correct prediction. Write a sentence why these errors might have happened.\n",
    "\n",
    "Look at the `fast-frugal.png` image in this directory. Pretty fancy, right? It is an example of a fancy kind of tree used to help doctors make decisions about heart disease. Without worrying too much about what each node means, discuss why this graph would be preferrable to the outputs of a logistic regression. How could the visual be improved?\n",
    "\n",
    "\n",
    "## Bonus: Plotting Our Tree\n",
    "\n",
    "The code below will generate a pdf with a visual representation of our tree model `dtree`.\n",
    "\n",
    "Warning: you need to have graphviz installed in python (via pip) and\n",
    "the back-end graphviz library installed on your computer. \n",
    "\n",
    "Warning 2: putting imports at the bottom of your notebooks is bad practice, \n",
    "I did it to prevent errors on everyone else's machine.\n",
    "\n",
    "We will make sure you can see this after class today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "made_it = np.where(y == 1, \"made it\", \"didn't make it\")\n",
    "\n",
    "dot_data = tree.export_graphviz(dtree,\n",
    "                                feature_names=X.columns,\n",
    "                                class_names = made_it,\n",
    "                                out_file=None, filled=True, rounded=True,\n",
    "                                special_characters=True) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"ncaa\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
